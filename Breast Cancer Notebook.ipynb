{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0      842302         M        17.99         10.38          122.80     1001.0   \n1      842517         M        20.57         17.77          132.90     1326.0   \n2    84300903         M        19.69         21.25          130.00     1203.0   \n3    84348301         M        11.42         20.38           77.58      386.1   \n4    84358402         M        20.29         14.34          135.10     1297.0   \n..        ...       ...          ...           ...             ...        ...   \n564    926424         M        21.56         22.39          142.00     1479.0   \n565    926682         M        20.13         28.25          131.20     1261.0   \n566    926954         M        16.60         28.08          108.30      858.1   \n567    927241         M        20.60         29.33          140.10     1265.0   \n568     92751         B         7.76         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0            0.11840           0.27760         0.30010              0.14710   \n1            0.08474           0.07864         0.08690              0.07017   \n2            0.10960           0.15990         0.19740              0.12790   \n3            0.14250           0.28390         0.24140              0.10520   \n4            0.10030           0.13280         0.19800              0.10430   \n..               ...               ...             ...                  ...   \n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0    ...          17.33           184.60      2019.0           0.16220   \n1    ...          23.41           158.80      1956.0           0.12380   \n2    ...          25.53           152.50      1709.0           0.14440   \n3    ...          26.50            98.87       567.7           0.20980   \n4    ...          16.67           152.20      1575.0           0.13740   \n..   ...            ...              ...         ...               ...   \n564  ...          26.40           166.10      2027.0           0.14100   \n565  ...          38.25           155.00      1731.0           0.11660   \n566  ...          34.12           126.70      1124.0           0.11390   \n567  ...          39.42           184.60      1821.0           0.16500   \n568  ...          30.37            59.16       268.6           0.08996   \n\n     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0              0.66560           0.7119                0.2654          0.4601   \n1              0.18660           0.2416                0.1860          0.2750   \n2              0.42450           0.4504                0.2430          0.3613   \n3              0.86630           0.6869                0.2575          0.6638   \n4              0.20500           0.4000                0.1625          0.2364   \n..                 ...              ...                   ...             ...   \n564            0.21130           0.4107                0.2216          0.2060   \n565            0.19220           0.3215                0.1628          0.2572   \n566            0.30940           0.3403                0.1418          0.2218   \n567            0.86810           0.9387                0.2650          0.4087   \n568            0.06444           0.0000                0.0000          0.2871   \n\n     fractal_dimension_worst  Unnamed: 32  \n0                    0.11890          NaN  \n1                    0.08902          NaN  \n2                    0.08758          NaN  \n3                    0.17300          NaN  \n4                    0.07678          NaN  \n..                       ...          ...  \n564                  0.07115          NaN  \n565                  0.06637          NaN  \n566                  0.07820          NaN  \n567                  0.12400          NaN  \n568                  0.07039          NaN  \n\n[569 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>926424</td>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>926682</td>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>926954</td>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>927241</td>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>92751</td>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "y = data['diagnosis'].map({'M':0,'B':1})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "x= data.drop(columns=['id','diagnosis','Unnamed: 32'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0          17.99         10.38          122.80     1001.0          0.11840   \n1          20.57         17.77          132.90     1326.0          0.08474   \n2          19.69         21.25          130.00     1203.0          0.10960   \n3          11.42         20.38           77.58      386.1          0.14250   \n4          20.29         14.34          135.10     1297.0          0.10030   \n..           ...           ...             ...        ...              ...   \n564        21.56         22.39          142.00     1479.0          0.11100   \n565        20.13         28.25          131.20     1261.0          0.09780   \n566        16.60         28.08          108.30      858.1          0.08455   \n567        20.60         29.33          140.10     1265.0          0.11780   \n568         7.76         24.54           47.92      181.0          0.05263   \n\n     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0             0.27760         0.30010              0.14710         0.2419   \n1             0.07864         0.08690              0.07017         0.1812   \n2             0.15990         0.19740              0.12790         0.2069   \n3             0.28390         0.24140              0.10520         0.2597   \n4             0.13280         0.19800              0.10430         0.1809   \n..                ...             ...                  ...            ...   \n564           0.11590         0.24390              0.13890         0.1726   \n565           0.10340         0.14400              0.09791         0.1752   \n566           0.10230         0.09251              0.05302         0.1590   \n567           0.27700         0.35140              0.15200         0.2397   \n568           0.04362         0.00000              0.00000         0.1587   \n\n     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n0                   0.07871  ...        25.380          17.33   \n1                   0.05667  ...        24.990          23.41   \n2                   0.05999  ...        23.570          25.53   \n3                   0.09744  ...        14.910          26.50   \n4                   0.05883  ...        22.540          16.67   \n..                      ...  ...           ...            ...   \n564                 0.05623  ...        25.450          26.40   \n565                 0.05533  ...        23.690          38.25   \n566                 0.05648  ...        18.980          34.12   \n567                 0.07016  ...        25.740          39.42   \n568                 0.05884  ...         9.456          30.37   \n\n     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n0             184.60      2019.0           0.16220            0.66560   \n1             158.80      1956.0           0.12380            0.18660   \n2             152.50      1709.0           0.14440            0.42450   \n3              98.87       567.7           0.20980            0.86630   \n4             152.20      1575.0           0.13740            0.20500   \n..               ...         ...               ...                ...   \n564           166.10      2027.0           0.14100            0.21130   \n565           155.00      1731.0           0.11660            0.19220   \n566           126.70      1124.0           0.11390            0.30940   \n567           184.60      1821.0           0.16500            0.86810   \n568            59.16       268.6           0.08996            0.06444   \n\n     concavity_worst  concave points_worst  symmetry_worst  \\\n0             0.7119                0.2654          0.4601   \n1             0.2416                0.1860          0.2750   \n2             0.4504                0.2430          0.3613   \n3             0.6869                0.2575          0.6638   \n4             0.4000                0.1625          0.2364   \n..               ...                   ...             ...   \n564           0.4107                0.2216          0.2060   \n565           0.3215                0.1628          0.2572   \n566           0.3403                0.1418          0.2218   \n567           0.9387                0.2650          0.4087   \n568           0.0000                0.0000          0.2871   \n\n     fractal_dimension_worst  \n0                    0.11890  \n1                    0.08902  \n2                    0.08758  \n3                    0.17300  \n4                    0.07678  \n..                       ...  \n564                  0.07115  \n565                  0.06637  \n566                  0.07820  \n567                  0.12400  \n568                  0.07039  \n\n[569 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>25.380</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>24.990</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>23.570</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>14.910</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>22.540</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>0.1726</td>\n      <td>0.05623</td>\n      <td>...</td>\n      <td>25.450</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.1752</td>\n      <td>0.05533</td>\n      <td>...</td>\n      <td>23.690</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.1590</td>\n      <td>0.05648</td>\n      <td>...</td>\n      <td>18.980</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.2397</td>\n      <td>0.07016</td>\n      <td>...</td>\n      <td>25.740</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1587</td>\n      <td>0.05884</td>\n      <td>...</td>\n      <td>9.456</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 30 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "from syft.workers.websocket_client import WebsocketClientWorker\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from syft.frameworks.torch.fl import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.2682, -0.9121, -1.1762,  ...,  0.6511,  0.3326,  2.2737],\n        [ 0.0523,  0.8209,  0.0854,  ...,  0.3306, -0.3190, -0.0359],\n        [-0.3841,  2.4745, -0.4371,  ..., -0.7613, -0.7815, -1.0531],\n        ...,\n        [ 0.2065, -0.3544,  0.1742,  ..., -0.4838,  1.1146, -0.6167],\n        [-0.6634, -0.4193, -0.6928,  ..., -1.0974,  0.4788, -1.0030],\n        [ 0.0319,  0.3354,  0.0282,  ...,  0.2954, -0.5797, -0.3045]],\n       dtype=torch.float64)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "torch.tensor(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "args = []\n",
    "abort_after_one = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import run_websocket_client as rwc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Namespace(batch_size=8, cuda=False, epochs=10, federate_after_n_batches=10, lr=0.01, save_model=False, seed=1, test_batch_size=1000, use_virtual=False, verbose=False)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "args = rwc.define_and_get_arguments(args=args)\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[<WebsocketClientWorker id:alice #tensors local:0 #tensors remote: 0>, <WebsocketClientWorker id:bob #tensors local:0 #tensors remote: 0>, <WebsocketClientWorker id:charlie #tensors local:0 #tensors remote: 0>]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket)\n",
    "charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "\n",
    "workers = [alice, bob, charlie]\n",
    "print(workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'{}'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "bob.list_tensors_remote()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "basedataset = BaseDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(np.array(Y_train), dtype=torch.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([426, 30])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "basedataset.data.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    basedataset.federate(tuple(workers)),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    iter_per_worker=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "testdataset = BaseDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(np.array(Y_test), dtype=torch.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testdataset,\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "BreastCancerNet(\n",
      "  (fc): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = rwc.BreastCancerNet().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d) - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{92591050960: <Plan Plan id:92591050960 owner:bob Tags: #fss_eq_plan_1 built>,\n 57981120932: <Plan Plan id:57981120932 owner:bob Tags: #fss_eq_plan_2 built>,\n 40318121759: <Plan Plan id:40318121759 owner:bob Tags: #fss_comp_plan_1 built>,\n 41488511919: <Plan Plan id:41488511919 owner:bob Tags: #fss_comp_plan_2 built>,\n 49265383058: <Plan Plan id:49265383058 owner:bob Tags: #xor_add_1 built>,\n 83337299896: <Plan Plan id:83337299896 owner:bob Tags: #xor_add_2 built>}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ],
   "source": [
    "bob._objects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Starting epoch 1/10\n",
      "Starting epoch 2/10\n",
      "Starting epoch 3/10\n",
      "Starting epoch 4/10\n",
      "Starting epoch 5/10\n",
      "Starting epoch 6/10\n",
      "Starting epoch 7/10\n",
      "Starting epoch 8/10\n",
      "Starting epoch 9/10\n",
      "Starting epoch 10/10\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "2020-05-26 16:55:16,129 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:16,175 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.868244\n",
      "2020-05-26 16:55:16,247 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.680070\n",
      "2020-05-26 16:55:16,326 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.572076\n",
      "2020-05-26 16:55:16,401 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.666906\n",
      "2020-05-26 16:55:16,476 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.893487\n",
      "2020-05-26 16:55:16,561 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.590089\n",
      "2020-05-26 16:55:16,631 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.630080\n",
      "2020-05-26 16:55:16,704 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.548413\n",
      "2020-05-26 16:55:16,749 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.853878\n",
      "2020-05-26 16:55:16,908 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.602889\n",
      "2020-05-26 16:55:16,992 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.636976\n",
      "2020-05-26 16:55:17,075 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.579869\n",
      "2020-05-26 16:55:17,894 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:17,987 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.595428\n",
      "2020-05-26 16:55:18,132 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.521288\n",
      "2020-05-26 16:55:18,271 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.548584\n",
      "2020-05-26 16:55:18,358 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.548751\n",
      "2020-05-26 16:55:18,452 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.515478\n",
      "2020-05-26 16:55:18,563 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.471325\n",
      "2020-05-26 16:55:18,677 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.609120\n",
      "2020-05-26 16:55:18,762 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.697818\n",
      "2020-05-26 16:55:18,831 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.523871\n",
      "2020-05-26 16:55:18,897 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:18,911 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "C:\\Users\\lobao\\AppData\\Roaming\\Python\\Python37\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\native.py:397: UserWarning: Using a target size (torch.Size([143])) that is different to the input size (torch.Size([143, 1])) is deprecated. Please ensure they have the same size.\n",
      "  response = command_method(*args_, **kwargs_)\n",
      "2020-05-26 16:55:18,916 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:18,917 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.4883, Accuracy: 128/143 (90%)\n",
      "\n",
      "2020-05-26 16:55:20,001 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:20,037 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.532514\n",
      "2020-05-26 16:55:20,137 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.501874\n",
      "2020-05-26 16:55:20,230 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.395741\n",
      "2020-05-26 16:55:20,385 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.474583\n",
      "2020-05-26 16:55:20,439 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.444361\n",
      "2020-05-26 16:55:20,523 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.540605\n",
      "2020-05-26 16:55:20,608 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.465937\n",
      "2020-05-26 16:55:20,704 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.416993\n",
      "2020-05-26 16:55:20,755 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.435961\n",
      "2020-05-26 16:55:20,856 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.450661\n",
      "2020-05-26 16:55:20,951 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.420206\n",
      "2020-05-26 16:55:21,100 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.461292\n",
      "2020-05-26 16:55:21,916 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:21,962 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.485029\n",
      "2020-05-26 16:55:22,061 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.442081\n",
      "2020-05-26 16:55:22,155 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.431718\n",
      "2020-05-26 16:55:22,271 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.618281\n",
      "2020-05-26 16:55:22,387 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.348143\n",
      "2020-05-26 16:55:22,477 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.314530\n",
      "2020-05-26 16:55:22,549 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.467783\n",
      "2020-05-26 16:55:22,684 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.411638\n",
      "2020-05-26 16:55:22,777 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.445866\n",
      "2020-05-26 16:55:22,829 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:22,841 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:22,846 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:22,847 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.3726, Accuracy: 131/143 (92%)\n",
      "\n",
      "2020-05-26 16:55:23,864 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:23,892 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.402557\n",
      "2020-05-26 16:55:23,995 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.474830\n",
      "2020-05-26 16:55:24,082 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.278060\n",
      "2020-05-26 16:55:24,164 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.343659\n",
      "2020-05-26 16:55:24,227 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.359471\n",
      "2020-05-26 16:55:24,345 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.483320\n",
      "2020-05-26 16:55:24,440 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.367992\n",
      "2020-05-26 16:55:24,523 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.431605\n",
      "2020-05-26 16:55:24,558 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.504384\n",
      "2020-05-26 16:55:24,696 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.309526\n",
      "2020-05-26 16:55:24,785 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.331494\n",
      "2020-05-26 16:55:24,867 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.315491\n",
      "2020-05-26 16:55:25,589 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:25,637 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.292849\n",
      "2020-05-26 16:55:25,734 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.400157\n",
      "2020-05-26 16:55:25,831 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.288810\n",
      "2020-05-26 16:55:25,943 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.384795\n",
      "2020-05-26 16:55:26,039 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.251373\n",
      "2020-05-26 16:55:26,130 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.380779\n",
      "2020-05-26 16:55:26,199 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.367402\n",
      "2020-05-26 16:55:26,370 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.393179\n",
      "2020-05-26 16:55:26,488 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.255461\n",
      "2020-05-26 16:55:26,558 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:26,571 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:26,575 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:26,576 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.3128, Accuracy: 134/143 (94%)\n",
      "\n",
      "2020-05-26 16:55:27,575 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:27,604 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.270445\n",
      "2020-05-26 16:55:27,700 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.244460\n",
      "2020-05-26 16:55:27,790 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.168382\n",
      "2020-05-26 16:55:27,882 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.275786\n",
      "2020-05-26 16:55:27,937 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.202585\n",
      "2020-05-26 16:55:28,033 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.321282\n",
      "2020-05-26 16:55:28,153 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.195295\n",
      "2020-05-26 16:55:28,345 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.358251\n",
      "2020-05-26 16:55:28,399 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.255429\n",
      "2020-05-26 16:55:28,492 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.388525\n",
      "2020-05-26 16:55:28,583 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.297788\n",
      "2020-05-26 16:55:28,734 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.215856\n",
      "2020-05-26 16:55:29,496 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:29,535 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.319703\n",
      "2020-05-26 16:55:29,637 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.289403\n",
      "2020-05-26 16:55:29,723 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.359720\n",
      "2020-05-26 16:55:29,799 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.356867\n",
      "2020-05-26 16:55:29,886 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.193520\n",
      "2020-05-26 16:55:29,975 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.446038\n",
      "2020-05-26 16:55:30,049 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.242156\n",
      "2020-05-26 16:55:30,168 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.284067\n",
      "2020-05-26 16:55:30,279 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.267535\n",
      "2020-05-26 16:55:30,332 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:30,349 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:30,353 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:30,354 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.2758, Accuracy: 136/143 (95%)\n",
      "\n",
      "2020-05-26 16:55:31,343 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:31,369 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.201290\n",
      "2020-05-26 16:55:31,475 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.267831\n",
      "2020-05-26 16:55:31,563 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.445804\n",
      "2020-05-26 16:55:31,770 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.258655\n",
      "2020-05-26 16:55:31,823 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.194744\n",
      "2020-05-26 16:55:31,919 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.300647\n",
      "2020-05-26 16:55:32,010 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.406212\n",
      "2020-05-26 16:55:32,144 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.352916\n",
      "2020-05-26 16:55:32,191 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.183363\n",
      "2020-05-26 16:55:32,301 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.171929\n",
      "2020-05-26 16:55:32,383 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.313966\n",
      "2020-05-26 16:55:32,510 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.286031\n",
      "2020-05-26 16:55:33,272 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:33,314 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.248542\n",
      "2020-05-26 16:55:33,411 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.374604\n",
      "2020-05-26 16:55:33,495 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.349162\n",
      "2020-05-26 16:55:33,567 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.304903\n",
      "2020-05-26 16:55:33,733 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.260436\n",
      "2020-05-26 16:55:33,842 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.349263\n",
      "2020-05-26 16:55:33,913 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.166136\n",
      "2020-05-26 16:55:33,997 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.277491\n",
      "2020-05-26 16:55:34,176 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.329215\n",
      "2020-05-26 16:55:34,244 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:34,262 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:34,266 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:34,267 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.2505, Accuracy: 136/143 (95%)\n",
      "\n",
      "2020-05-26 16:55:35,189 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:35,225 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.266457\n",
      "2020-05-26 16:55:35,328 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.179624\n",
      "2020-05-26 16:55:35,414 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.419065\n",
      "2020-05-26 16:55:35,523 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.287402\n",
      "2020-05-26 16:55:35,578 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.177936\n",
      "2020-05-26 16:55:35,677 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.218483\n",
      "2020-05-26 16:55:35,765 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.135619\n",
      "2020-05-26 16:55:35,901 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.263431\n",
      "2020-05-26 16:55:35,944 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.223982\n",
      "2020-05-26 16:55:36,043 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.150998\n",
      "2020-05-26 16:55:36,128 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.302288\n",
      "2020-05-26 16:55:36,264 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.263637\n",
      "2020-05-26 16:55:37,013 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:37,058 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.375383\n",
      "2020-05-26 16:55:37,149 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.365344\n",
      "2020-05-26 16:55:37,230 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.188677\n",
      "2020-05-26 16:55:37,304 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.282833\n",
      "2020-05-26 16:55:37,471 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.272707\n",
      "2020-05-26 16:55:37,572 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.525970\n",
      "2020-05-26 16:55:37,643 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.424393\n",
      "2020-05-26 16:55:37,730 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.215713\n",
      "2020-05-26 16:55:37,856 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.325999\n",
      "2020-05-26 16:55:37,931 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:37,945 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:37,951 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:37,953 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.2319, Accuracy: 136/143 (95%)\n",
      "\n",
      "2020-05-26 16:55:38,935 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:38,968 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.185720\n",
      "2020-05-26 16:55:39,057 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.263316\n",
      "2020-05-26 16:55:39,144 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.085251\n",
      "2020-05-26 16:55:39,234 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.394426\n",
      "2020-05-26 16:55:39,329 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.252047\n",
      "2020-05-26 16:55:39,419 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.246731\n",
      "2020-05-26 16:55:39,502 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.177325\n",
      "2020-05-26 16:55:39,586 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.130329\n",
      "2020-05-26 16:55:39,629 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.344053\n",
      "2020-05-26 16:55:39,796 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.134747\n",
      "2020-05-26 16:55:39,922 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.272082\n",
      "2020-05-26 16:55:40,024 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.220533\n",
      "2020-05-26 16:55:40,769 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:40,819 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.213789\n",
      "2020-05-26 16:55:40,912 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.344062\n",
      "2020-05-26 16:55:41,000 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.162402\n",
      "2020-05-26 16:55:41,094 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.386495\n",
      "2020-05-26 16:55:41,211 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.417114\n",
      "2020-05-26 16:55:41,294 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.275509\n",
      "2020-05-26 16:55:41,357 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.197793\n",
      "2020-05-26 16:55:41,545 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.153687\n",
      "2020-05-26 16:55:41,642 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.176143\n",
      "2020-05-26 16:55:41,700 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:41,715 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:41,718 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:41,720 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.2173, Accuracy: 135/143 (94%)\n",
      "\n",
      "2020-05-26 16:55:42,740 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:42,778 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.369449\n",
      "2020-05-26 16:55:42,881 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.148056\n",
      "2020-05-26 16:55:42,973 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.148418\n",
      "2020-05-26 16:55:43,076 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.260110\n",
      "2020-05-26 16:55:43,123 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.374875\n",
      "2020-05-26 16:55:43,218 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.110846\n",
      "2020-05-26 16:55:43,304 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.123415\n",
      "2020-05-26 16:55:43,398 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.236831\n",
      "2020-05-26 16:55:43,462 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.187676\n",
      "2020-05-26 16:55:43,560 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.211177\n",
      "2020-05-26 16:55:43,642 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.209194\n",
      "2020-05-26 16:55:43,724 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.210563\n",
      "2020-05-26 16:55:44,522 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:44,562 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.213864\n",
      "2020-05-26 16:55:44,661 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.277531\n",
      "2020-05-26 16:55:44,745 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.248303\n",
      "2020-05-26 16:55:44,814 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.137061\n",
      "2020-05-26 16:55:45,059 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.286774\n",
      "2020-05-26 16:55:45,163 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.226990\n",
      "2020-05-26 16:55:45,234 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.184775\n",
      "2020-05-26 16:55:45,326 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.203306\n",
      "2020-05-26 16:55:45,552 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.110882\n",
      "2020-05-26 16:55:45,628 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:45,647 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:45,651 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:45,653 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.2057, Accuracy: 135/143 (94%)\n",
      "\n",
      "2020-05-26 16:55:46,650 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:46,681 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.164358\n",
      "2020-05-26 16:55:46,800 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.351951\n",
      "2020-05-26 16:55:46,891 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.156427\n",
      "2020-05-26 16:55:47,026 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.186464\n",
      "2020-05-26 16:55:47,068 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.368090\n",
      "2020-05-26 16:55:47,179 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.135822\n",
      "2020-05-26 16:55:47,266 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.246008\n",
      "2020-05-26 16:55:47,396 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.208077\n",
      "2020-05-26 16:55:47,459 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.267584\n",
      "2020-05-26 16:55:47,572 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.211824\n",
      "2020-05-26 16:55:47,695 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.216907\n",
      "2020-05-26 16:55:47,789 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.109827\n",
      "2020-05-26 16:55:48,680 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:48,763 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.280513\n",
      "2020-05-26 16:55:48,915 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.193892\n",
      "2020-05-26 16:55:49,066 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.122175\n",
      "2020-05-26 16:55:49,142 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.466442\n",
      "2020-05-26 16:55:49,241 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.295326\n",
      "2020-05-26 16:55:49,338 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.234224\n",
      "2020-05-26 16:55:49,446 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.356773\n",
      "2020-05-26 16:55:49,539 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.122757\n",
      "2020-05-26 16:55:49,623 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.171290\n",
      "2020-05-26 16:55:49,680 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:49,697 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:49,701 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:49,703 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.1961, Accuracy: 135/143 (94%)\n",
      "\n",
      "2020-05-26 16:55:50,717 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [0, 10]\n",
      "2020-05-26 16:55:50,745 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/10 (0%)]\tLoss: 0.137352\n",
      "2020-05-26 16:55:50,842 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/10 (30%)]\tLoss: 0.158375\n",
      "2020-05-26 16:55:50,930 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/10 (60%)]\tLoss: 0.249768\n",
      "2020-05-26 16:55:51,017 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [9/10 (90%)]\tLoss: 0.200700\n",
      "2020-05-26 16:55:51,126 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/10 (0%)]\tLoss: 0.365626\n",
      "2020-05-26 16:55:51,217 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/10 (30%)]\tLoss: 0.113112\n",
      "2020-05-26 16:55:51,307 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/10 (60%)]\tLoss: 0.260972\n",
      "2020-05-26 16:55:51,410 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [9/10 (90%)]\tLoss: 0.235692\n",
      "2020-05-26 16:55:51,526 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/10 (0%)]\tLoss: 0.105661\n",
      "2020-05-26 16:55:51,620 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/10 (30%)]\tLoss: 0.106723\n",
      "2020-05-26 16:55:51,702 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/10 (60%)]\tLoss: 0.177233\n",
      "2020-05-26 16:55:51,790 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [9/10 (90%)]\tLoss: 0.151570\n",
      "2020-05-26 16:55:52,601 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [10, 20]\n",
      "2020-05-26 16:55:52,645 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [0/8 (0%)]\tLoss: 0.172648\n",
      "2020-05-26 16:55:52,746 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [3/8 (38%)]\tLoss: 0.298808\n",
      "2020-05-26 16:55:52,835 DEBUG run_websocket_client.py(l:68) - Train Worker alice: [6/8 (75%)]\tLoss: 0.150115\n",
      "2020-05-26 16:55:52,907 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [0/8 (0%)]\tLoss: 0.246498\n",
      "2020-05-26 16:55:53,004 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [3/8 (38%)]\tLoss: 0.197751\n",
      "2020-05-26 16:55:53,089 DEBUG run_websocket_client.py(l:68) - Train Worker bob: [6/8 (75%)]\tLoss: 0.253500\n",
      "2020-05-26 16:55:53,163 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [0/8 (0%)]\tLoss: 0.285930\n",
      "2020-05-26 16:55:53,327 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [3/8 (38%)]\tLoss: 0.231681\n",
      "2020-05-26 16:55:53,435 DEBUG run_websocket_client.py(l:68) - Train Worker charlie: [6/8 (75%)]\tLoss: 0.206065\n",
      "2020-05-26 16:55:53,498 DEBUG run_websocket_client.py(l:120) - Starting training round, batches [20, 30]\n",
      "2020-05-26 16:55:53,515 DEBUG run_websocket_client.py(l:132) - At least one worker ran out of data, stopping.\n",
      "2020-05-26 16:55:53,519 DEBUG run_websocket_client.py(l:156) - \n",
      "\n",
      "2020-05-26 16:55:53,520 INFO run_websocket_client.py(l:160) - Test set: Average loss: 0.1880, Accuracy: 135/143 (94%)\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"Starting epoch {}/{}\".format(epoch, args.epochs))\n",
    "    model = rwc.train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches, \n",
    "                      abort_after_one=abort_after_one)\n",
    "    rwc.test(model, device, test_loader)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}